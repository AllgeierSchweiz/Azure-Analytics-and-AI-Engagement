{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"font-size:25px; color:black;\"><u><i><b>Product Recommendations</b></i></u></p>\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Product recommendations is a filtering system that predicts and shows the items that a user would likely purchase based on their purchase history.\n",
        "</p>\n",
        "\n",
        "<p style=\"font-size:15px; color:#318f50;\">\n",
        "Note:\n",
        "</p>\n",
        "<p style=\"font-size:15px; color:#117d30;\">\n",
        " This notebook is written in Scala, and there is interoperability between Scala and Python code.\n",
        "</p>\n",
        "<p style=\"font-size:15px; color:#117d30;\">\n",
        "    <u> Steps: </u>\n",
        "</p>\n",
        "<p style=\"font-size:15px; color:#117d30;\">\n",
        "1) Data is ingested from Azure Synapse Data Warehouse using PySpark.\n",
        "</p>\n",
        "<p style=\"font-size:15px; color:#117d30;\">\n",
        "2) The model is trained using the PySpark ML-Lib recommendations module.\n",
        "</p>\n",
        "<p style=\"font-size:15px; color:#117d30;\">\n",
        "3) Product recommendations are generated for the user.\n",
        "</p>"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Connecting to Azure Synapse Data Warehouse*\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Connection to Azure Synapse Data Warehouse is initiated and the required data is ingested for processing.\n",
        "    The warehouse is connected with a single line of code. Just point to actions in a table, click on a new notebook, and then click on \"Load to DataFrame\".  </p>\n",
        "   <p style=\"font-size:16px; color:#117d30;\"> After providing the necessary details,  the required data is loaded in the form of a Spark dataframe.\n",
        "One magical line of code converts a dataframe from Scala to Python!\n",
        "</p>"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
        "from pyspark import SparkContext\n",
        "\n",
        "import traceback"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "df: org.apache.spark.sql.DataFrame = [customer_id: int, product_id: int ... 3 more fields]\nres10: Array[org.apache.spark.sql.Row] = Array([84793,25,White Shoes,1,0], [43603,5,Orange SurfBoard,2,1], [33925,29,Gray with white sole shoes,3,3], [83108,25,White Shoes,2,1], [34904,19,Yellow mature Dutch cheese ,3,3], [49590,21,Cheese circle,1,0], [95886,27,Pink Shoes,1,0], [39979,2,Retro surfboard,3,3], [58533,16,Turkish Lira,2,1], [61681,17,Wood and Cork Coaster,3,3])"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%spark\n",
        "val df = spark.read.sqlanalytics(\"SQLPool01.dbo.Customer_SalesLatest\") \n",
        "  df.head(10)\n",
        "  //Create a Temp view for using the dataframe from Scala to Python\n",
        "  df.createOrReplaceTempView (\"df\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "DataFrame[customer_id: int, product_id: int, product_name: string, total_quantity: int, rating: int]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "print(df)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "DataFrame[customer_id: int, product_id: int, product_name: string, total_quantity: int, rating: int]"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "rating"
            ],
            "values": [
              "customer_id"
            ],
            "yLabel": "customer_id",
            "xLabel": "rating",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": {
            "customer_id": {
              "0": 15840248,
              "1": 12289037,
              "3": 14460213,
              "5": 14908088
            }
          },
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "display(df)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 69,
          "data": {
            "text/plain": "2.4.4.dev0\nNone"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "import pyspark \n",
        "print(print(pyspark.__version__)) "
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
        "from pyspark import SparkContext\n",
        "\n",
        "import traceback"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "#Calling the dataframe df created in Scala to Python\n",
        "df = sqlContext.table(\"df\")\n",
        "# *********************\n",
        "\n",
        "\n",
        "Customer_data = df.select(\"customer_id\", \"product_id\", \"rating\")\n",
        "\n",
        "_toExplore = df.select(\"*\").toPandas()\n",
        "\n",
        "unique_users = _toExplore.customer_id.unique()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "customer_id  product_id                product_name  rating\n68971          85233          22                  Wineglass        5\n776197         43211          18               French cheese       3\n444660         60281           3            Blue Surf Board        1\n1392226        22685          25                 White Shoes       5\n97619           5450          11             Black corkscrew       1\n1181750        69360          13               Brown Coaster       1\n1183253          400          20                Cheese chunk       5\n81326          12576          26                 Black Shoes       5\n454659         45165          29  Gray with white sole shoes       3\n1410239        30297           7               Red Surfboard       0"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "display(_toExplore[['customer_id', 'product_id', 'product_name', 'rating']].sample(n=10))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Training the model***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    \n",
        "    The machine learning model used is the recommendation module present in\n",
        "    pyspark.mllib.\n",
        "</p>\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Using the ALS (alternating least square) method, we can train the model, which takes a list of tuples consisting mainly of \"userID\", \"productID\" and \"rating\".\n",
        "</p>\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    The parameters passed in training the model are a list of tuples, no. of iterations, and rank.\n",
        "</p>\n",
        "<!-- <p style=\"font-size:16px; color:#117d30;\">\n",
        "    Rank is the no. of features to use while training the model.\n",
        "</p> -->\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "    Training model for predicting the recommendation on given set of input\n",
        "  \"\"\"\n",
        "  try:\n",
        "    rank = 5\n",
        "    numIterations = 10\n",
        "    print(\"Training model.........\")\n",
        "    \n",
        "    model = ALS.train(Customer_data, rank, numIterations, seed=30)\n",
        "    # model.save(sc, PATH)\n",
        "    return model\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return \"Error while loading model\""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 74,
          "data": {
            "text/plain": "Training model........."
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "trained_model = train_model()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *** Loading the model***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Once the model is trained, it is saved on the required path for loading the weights generated after training the model. \n",
        "</p>\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Using the loaded model, we can generate product recommendations for customers. \n",
        "</p>\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "def load_model():\n",
        "  try:\n",
        "    saved_model = MatrixFactorizationModel.load(sc, PATH)\n",
        "    return saved_model\n",
        "  except:\n",
        "    return \"Model not loaded\""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Product Recommender***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    The \"recommend_products\" method is a main wrapper function which consists of certain other methods to  recommend items to the user\". \n",
        "</p>\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "def recommend_products(user_id, num):\n",
        "  \"\"\"\n",
        "    Function for recommending products to user\n",
        "    \n",
        "    Parameters:\n",
        "      user_id    : int\n",
        "      no of product to recommend : int \n",
        "  \"\"\"\n",
        "  try:\n",
        "    user_id = int(user_id)\n",
        "      \n",
        "    check_user = validate_user(user_id)\n",
        "    \n",
        "    if len(check_user) == 0: return \"User does not exist\"\n",
        "        #       products = top_products()\n",
        "        #       return products\n",
        "        \n",
        "    data = trained_model.recommendProducts(user_id ,num)\n",
        "    result = map_products(data)\n",
        "    return result\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return \"Error while recommending product\""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Validate user***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    The \"validate_user\" method is used to verify if a particualar user_id exists in the database.\n",
        "</p>\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "def validate_user(user_id):\n",
        "  \"\"\"\n",
        "    Checks if user exist in database\n",
        "    \n",
        "    Parameters:\n",
        "    \n",
        "      user_id : int\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if user_id is not None:\n",
        "      user = df.filter(df.customer_id == user_id).collect()\n",
        "      return user\n",
        "    else:\n",
        "      return \"Please pass user_id\"\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return \"Error\""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Verify products***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    The \"verify_product\" method is used for checking if a product exists in the database.\n",
        "</p>"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "def verify_product(product):\n",
        "  \"\"\"\n",
        "    Validating if product exist in database\n",
        "  \"\"\"\n",
        "  try:\n",
        "    prod = df.filter(df.product_id == product).collect()\n",
        "    return prod\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return \"Error\""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Map products***\n",
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    The \"map_products\" method is used to map a  product id with a product name.\n",
        "</p>"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "def map_products(data):\n",
        "  try:\n",
        "    dataFrame = pd.DataFrame(data)\n",
        "    dataFrame = dataFrame[['product', 'rating']]\n",
        "    dataFrame = pd.DataFrame(dataFrame)\n",
        "    # temp_dict = _toExplore.set_index('product_id').to_dict()['product_name']\n",
        "    # mapped_prod = dataFrame.replace(temp_dict)\n",
        "    dataFrame.rename(columns={'product':'Recommended-Products','rating':'Rating'}, inplace=True)\n",
        "    dataFrame.index.name = None\n",
        "    return dataFrame.sample(n=5)\n",
        "  except:\n",
        "    traceback.print_exc()\n",
        "    return \"Error\"\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "new = trained_model.recommendProductsForUsers(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 81,
          "data": {
            "text/plain": "userid Recommendation1       ...       Recommendation4 Recommendation5\n0   18624              12       ...                     5               9\n1   80704              26       ...                    32              12\n2    3456              10       ...                     5              31\n3    6400              12       ...                     5              10\n4   24384              30       ...                    10              15\n5   29696              20       ...                     8              13\n6   61696              24       ...                    29               4\n7   20160              24       ...                    19              22\n8   59200              10       ...                    16               9\n9   74816               7       ...                    24               4\n10  66112              24       ...                    21               4\n11  83904              10       ...                    31              30\n12  33920              31       ...                     3              19\n13  64960              30       ...                    19              22\n14  88704              10       ...                    31              30\n15   4992              12       ...                     8              20\n16  79680              24       ...                     4               2\n17  66368              24       ...                     4              17\n18  58240              29       ...                     4               6\n19  58880              12       ...                    32              26\n20  62912              10       ...                    12              30\n21   4224              18       ...                    15              29\n22  75456              16       ...                    27              22\n23  59456              24       ...                    21              27\n24  64320              31       ...                     3              10\n\n[25 rows x 6 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "data=new.collect()\n",
        "allproduct=[]\n",
        "alluser=[]\n",
        "for  h in data:\n",
        "    t=str(h)\n",
        "    res=re.split('[\\W]+', t)\n",
        "    userid=[]\n",
        "    product=[]\n",
        "    for w in range(0,len(res)):\n",
        "        if res[w]=='user':\n",
        "            userid.append(res[w+1])\n",
        "        elif res[w]=='product':\n",
        "            product.append(res[w+1])\n",
        "    allproduct.append(product)\n",
        "    alluser.append(userid[0])\n",
        "recomm_df1=pd.DataFrame(alluser,columns=['userid'])\n",
        "recomm_df2=pd.DataFrame(allproduct,columns=['Recommendation1','Recommendation2','Recommendation3','Recommendation4','Recommendation5'])\n",
        "\n",
        "FinalData=pd.concat([recomm_df1,recomm_df2],sort=True,axis=1)\n",
        "# print(FinalData)\n",
        "FinalData.head(n=25)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"font-size:16px; color:#117d30;\">\n",
        "    Finally, call the main function and pass the two parameters \"user_id\" and \"product_id\" to generate product recommendations.\n",
        "</p>\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 82,
          "data": {
            "text/plain": "Recommended-Products    Rating\n4                     5  4.520149\n6                    25  4.364865\n2                    31  4.875994\n5                    16  4.458258\n3                    30  4.708153"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%pyspark\n",
        "output = recommend_products(user_id=1533, num=7)\n",
        "output"
      ],
      "attachments": {}
    }
  ]
}